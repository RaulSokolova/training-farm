2023-10-03 12:40:30,839 [ERROR] trainer5/trainer5.py Failed to reconnect: Already connected
Traceback (most recent call last):
  File "/Users/miguellopes/Documents/pod-trader/trainer5/trainer5.py", line 102, in disconnect
    sio.connect('http://localhost:5678')
  File "/Users/miguellopes/miniforge3/envs/trader/lib/python3.10/site-packages/socketio/client.py", line 306, in connect
    raise exceptions.ConnectionError('Already connected')
socketio.exceptions.ConnectionError: Already connected
2023-10-03 12:40:32,598 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 14:15:41,370 [ERROR] packet queue is empty, aborting
2023-10-03 17:16:50,056 [ERROR] packet queue is empty, aborting
2023-10-03 17:23:00,229 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-03 17:24:51,932 [INFO] | 2.00e+04       112  |     0.00    0.00  200000  |     0.00      0.00
2023-10-03 17:26:42,511 [INFO] | 4.00e+04       222  |     0.00    0.00  200000  |     0.00      0.01
2023-10-03 17:28:34,621 [INFO] | 6.00e+04       334  |     0.00    0.00  200000  |     0.00      0.01
2023-10-03 17:30:29,886 [INFO] | 8.00e+04       450  |     0.00    0.00  200000  |     0.00      0.02
2023-10-03 17:32:22,426 [INFO] | 1.00e+05       562  |     0.00    0.00  200000  |     0.00      0.01
2023-10-03 17:34:48,271 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-03 17:36:42,938 [INFO] | 2.00e+04       115  |   -79.57    2.26  200000  |     0.21      0.01
2023-10-03 17:38:36,687 [INFO] | 4.00e+04       228  |   -75.51    1.94  200000  |     0.29      0.01
2023-10-03 17:40:35,030 [INFO] | 6.00e+04       347  |   -77.27    1.63  200000  |     0.31      0.02
2023-10-03 17:42:33,278 [INFO] | 8.00e+04       465  |   -76.09    1.76  200000  |     0.13      0.03
2023-10-03 17:44:31,039 [INFO] | 1.00e+05       583  |   -77.10    2.46  200000  |     0.22      0.01
2023-10-05 10:36:39,692 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 10:40:49,533 [INFO] | 2.00e+04       250  |    17.99    6.26  200000  |     0.00      0.45
2023-10-05 10:45:09,516 [INFO] | 4.00e+04       510  |    12.83    3.35  200000  |     0.00      0.43
2023-10-05 10:49:19,333 [INFO] | 6.00e+04       760  |    22.27   10.60  200000  |     0.00      0.42
2023-10-05 10:53:24,159 [INFO] | 8.00e+04      1004  |    35.80    5.51  200000  |     0.00      0.45
2023-10-05 10:57:27,112 [INFO] | 1.00e+05      1247  |    72.36   29.28  200000  |     0.00      0.43
2023-10-05 11:06:00,596 [INFO] price_array: 72540
2023-10-05 11:06:00,599 [INFO] | load actor from: ./trained_models/trainer5-f2070-steps-200000[256, 128]-2019-01-01/actor.pth
2023-10-05 11:06:11,246 [INFO] Test Finished!
2023-10-05 11:06:11,247 [INFO] episode_return: 1.2669900227303204
2023-10-05 13:27:35,968 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 13:31:55,253 [INFO] | 2.00e+04       259  |    49.87    4.33  200000  |     0.00      0.44
2023-10-05 13:36:05,760 [INFO] | 4.00e+04       510  |    52.54    4.04  200000  |     0.00      0.43
2023-10-05 13:40:12,780 [INFO] | 6.00e+04       757  |    50.66    6.59  200000  |     0.00      0.44
2023-10-05 13:44:13,780 [INFO] | 8.00e+04       998  |    56.89    5.24  200000  |     0.00      0.44
2023-10-05 13:48:13,420 [INFO] | 1.00e+05      1237  |    57.77    5.49  200000  |     0.00      0.43
2023-10-05 13:56:43,815 [INFO] price_array: 72540
2023-10-05 13:56:43,817 [INFO] | load actor from: ./trained_models/trainer5-12298-steps-200000[256, 128]-2019-01-01/actor.pth
2023-10-05 13:56:53,749 [INFO] Test Finished!
2023-10-05 13:56:53,750 [INFO] episode_return: 1.2447993293238866
2023-10-05 14:53:16,639 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 14:57:15,031 [INFO] | 2.00e+04       238  |     0.46    0.72  200000  |     0.00      0.45
2023-10-05 15:01:07,093 [INFO] | 4.00e+04       470  |     0.62    1.65  200000  |     0.00      0.43
2023-10-05 15:05:04,849 [INFO] | 6.00e+04       708  |     0.24    0.54  200000  |     0.00      0.43
2023-10-05 15:09:05,066 [INFO] | 8.00e+04       948  |    -2.02    5.32  200000  |     0.00      0.43
2023-10-05 15:12:48,137 [INFO] | 1.00e+05      1171  |    -9.70    6.73  200000  |     0.00      0.43
2023-10-05 15:21:36,924 [INFO] price_array: 72540
2023-10-05 15:21:36,930 [INFO] | load actor from: ./trained_models/trainer5-60b55-steps-200000[256, 128, 64]-2019-01-01/actor.pth
2023-10-05 15:21:45,925 [INFO] Test Finished!
2023-10-05 15:21:45,926 [INFO] episode_return: 0.9046946525410183
2023-10-05 16:12:46,368 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 16:22:03,525 [INFO] | 2.00e+04       557  |    -5.97    6.60  300000  |     0.00      0.43
2023-10-05 16:30:31,355 [INFO] | 4.00e+04      1065  |    -4.34    8.77  300000  |     0.00      0.44
2023-10-05 16:38:13,361 [INFO] | 6.00e+04      1527  |   -10.17   14.84  300000  |     0.00      0.43
2023-10-05 16:46:03,911 [INFO] | 8.00e+04      1998  |   -30.13    8.77  300000  |     0.00      0.43
2023-10-05 16:54:01,230 [INFO] | 1.00e+05      2475  |   -28.39   28.96  300000  |     0.00      0.41
2023-10-05 17:03:13,600 [INFO] price_array: 72540
2023-10-05 17:03:13,608 [INFO] | load actor from: ./trained_models/trainer5-d4c0d-steps-300000[1024, 512]-2019-01-01/actor.pth
2023-10-05 17:03:25,924 [INFO] Test Finished!
2023-10-05 17:03:25,925 [INFO] episode_return: 0.9135487403336058
2023-10-05 17:58:12,659 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 18:01:58,335 [INFO] | 2.00e+04       226  |     9.87    3.18  200000  |     0.00      0.45
2023-10-05 18:05:44,549 [INFO] | 4.00e+04       452  |     9.61    3.72  200000  |     0.00      0.44
2023-10-05 18:09:26,252 [INFO] | 6.00e+04       674  |    13.65    6.80  200000  |     0.00      0.43
2023-10-05 18:13:21,101 [INFO] | 8.00e+04       908  |    17.01    4.27  200000  |     0.00      0.42
2023-10-05 18:17:05,716 [INFO] | 1.00e+05      1133  |    12.86    7.13  200000  |     0.00      0.43
2023-10-05 18:25:53,315 [INFO] price_array: 72540
2023-10-05 18:25:53,319 [INFO] | load actor from: ./trained_models/trainer5-1d976-steps-200000[256, 128]-2019-01-01/actor.pth
2023-10-05 18:26:02,834 [INFO] Test Finished!
2023-10-05 18:26:02,834 [INFO] episode_return: 0.970387280763926
2023-10-05 19:20:22,114 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 19:22:16,501 [INFO] | 2.00e+04       114  |    -0.05    0.03  100000  |     0.00      0.42
2023-10-05 19:24:12,678 [INFO] | 4.00e+04       231  |    -0.07    0.02  100000  |     0.00      0.42
2023-10-05 19:26:06,967 [INFO] | 6.00e+04       345  |    -0.06    0.03  100000  |     0.00      0.42
2023-10-05 19:28:01,923 [INFO] | 8.00e+04       460  |    -0.08    0.05  100000  |     0.00      0.43
2023-10-05 19:29:53,640 [INFO] | 1.00e+05       572  |    -0.07    0.05  100000  |     0.00      0.43
2023-10-05 19:39:20,352 [INFO] price_array: 72540
2023-10-05 19:39:20,355 [INFO] | load actor from: ./trained_models/trainer5-797be-steps-100000[256, 128, 64]-2019-01-01/actor.pth
2023-10-05 19:39:29,695 [INFO] Test Finished!
2023-10-05 19:39:29,696 [INFO] episode_return: 1.2749810967997552
2023-10-05 20:33:15,522 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 20:41:32,674 [INFO] | 2.00e+04       497  |   -26.71   17.49  300000  |     0.00      0.43
2023-10-05 20:49:13,975 [INFO] | 4.00e+04       958  |   -25.05    6.71  300000  |     0.00      0.43
2023-10-05 20:56:52,849 [INFO] | 6.00e+04      1417  |   -28.34    9.19  300000  |     0.00      0.43
2023-10-05 21:04:25,644 [INFO] | 8.00e+04      1870  |   -32.06   11.99  300000  |     0.00      0.41
2023-10-05 21:11:58,262 [INFO] | 1.00e+05      2323  |   -34.58   15.12  300000  |     0.00      0.43
2023-10-05 21:22:04,213 [INFO] price_array: 72540
2023-10-05 21:22:04,220 [INFO] | load actor from: ./trained_models/trainer5-35d9c-steps-300000[1024, 512]-2019-01-01/actor.pth
2023-10-05 21:22:15,585 [INFO] Test Finished!
2023-10-05 21:22:15,586 [INFO] episode_return: 1.1900338027658979
2023-10-05 22:18:30,014 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 22:22:45,087 [INFO] | 2.00e+04       255  |    -2.09    4.51  200000  |     0.00      0.42
2023-10-05 22:27:04,066 [INFO] | 4.00e+04       514  |    -4.46    4.32  200000  |     0.00      0.42
2023-10-05 22:31:27,407 [INFO] | 6.00e+04       777  |    -7.78    2.52  200000  |     0.00      0.43
2023-10-05 22:35:45,681 [INFO] | 8.00e+04      1036  |    -4.25    4.04  200000  |     0.00      0.43
2023-10-05 22:40:00,808 [INFO] | 1.00e+05      1291  |    -5.13    6.38  200000  |     0.00      0.43
2023-10-05 22:49:52,856 [INFO] price_array: 72540
2023-10-05 22:49:52,860 [INFO] | load actor from: ./trained_models/trainer5-f854f-steps-200000[256, 128]-2019-01-01/actor.pth
2023-10-05 22:50:02,622 [INFO] Test Finished!
2023-10-05 22:50:02,623 [INFO] episode_return: 1.4395571336486859
