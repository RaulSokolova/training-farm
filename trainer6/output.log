2023-10-05 10:13:33,131 [ERROR] trainer6 Failed to reconnect: Already connected
Traceback (most recent call last):
  File "/Users/miguellopes/Documents/pod-trader/trainer6/trainer6.py", line 109, in disconnect
    sio.connect('http://localhost:5678')
  File "/Users/miguellopes/miniforge3/envs/trader/lib/python3.10/site-packages/socketio/client.py", line 306, in connect
    raise exceptions.ConnectionError('Already connected')
socketio.exceptions.ConnectionError: Already connected
2023-10-05 10:40:07,498 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 10:42:14,877 [INFO] | 2.00e+04       127  |    -0.70    0.05  100000  |     0.00      0.43
2023-10-05 10:44:25,685 [INFO] | 4.00e+04       258  |    -0.69    0.06  100000  |     0.00      0.44
2023-10-05 10:46:29,126 [INFO] | 6.00e+04       382  |    -0.68    0.05  100000  |     0.00      0.44
2023-10-05 10:48:29,211 [INFO] | 8.00e+04       502  |    -0.69    0.03  100000  |     0.00      0.43
2023-10-05 10:50:32,252 [INFO] | 1.00e+05       625  |    -0.67    0.05  100000  |     0.00      0.45
2023-10-05 10:59:03,218 [INFO] price_array: 72540
2023-10-05 10:59:03,220 [INFO] | load actor from: ./trained_models/trainer6-03e47-steps-100000[256, 128]-2019-01-01/actor.pth
2023-10-05 10:59:13,431 [INFO] Test Finished!
2023-10-05 10:59:13,431 [INFO] episode_return: 1.130486465312116
2023-10-05 13:32:43,055 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 13:34:50,472 [INFO] | 2.00e+04       127  |    -0.63    0.07  100000  |     0.01      0.43
2023-10-05 13:36:56,012 [INFO] | 4.00e+04       253  |    -0.60    0.05  100000  |     0.00      0.44
2023-10-05 13:39:01,203 [INFO] | 6.00e+04       378  |    -0.89    0.28  100000  |     0.00      0.43
2023-10-05 13:41:02,244 [INFO] | 8.00e+04       499  |    -0.58    0.03  100000  |     0.00      0.42
2023-10-05 13:43:04,421 [INFO] | 1.00e+05       621  |    -0.55    0.05  100000  |     0.00      0.44
2023-10-05 13:51:39,305 [INFO] price_array: 72540
2023-10-05 13:51:39,309 [INFO] | load actor from: ./trained_models/trainer6-cd8ff-steps-100000[256, 128]-2019-01-01/actor.pth
2023-10-05 13:51:49,604 [INFO] Test Finished!
2023-10-05 13:51:49,606 [INFO] episode_return: 1.5002118825486825
2023-10-05 14:46:46,067 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 14:48:58,090 [INFO] | 2.00e+04       132  |    -0.03    0.14  100000  |     0.00      0.43
2023-10-05 14:51:11,622 [INFO] | 4.00e+04       266  |    -0.12    0.03  100000  |     0.00      0.44
2023-10-05 14:53:21,842 [INFO] | 6.00e+04       396  |    -0.11    0.09  100000  |     0.00      0.43
2023-10-05 14:55:34,106 [INFO] | 8.00e+04       528  |    -0.10    0.11  100000  |     0.00      0.42
2023-10-05 14:57:42,166 [INFO] | 1.00e+05       656  |    -0.15    0.07  100000  |     0.00      0.42
2023-10-05 15:07:10,217 [INFO] price_array: 72540
2023-10-05 15:07:10,219 [INFO] | load actor from: ./trained_models/trainer6-66468-steps-100000[128, 64, 32]-2019-01-01/actor.pth
2023-10-05 15:07:20,530 [INFO] Test Finished!
2023-10-05 15:07:20,530 [INFO] episode_return: 1.079917495179081
2023-10-05 15:58:16,636 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 16:04:03,922 [INFO] | 2.00e+04       347  |   -11.82   11.40  300000  |     0.00      0.43
2023-10-05 16:10:02,700 [INFO] | 4.00e+04       706  |   -26.03   28.83  300000  |     0.00      0.44
2023-10-05 16:16:10,566 [INFO] | 6.00e+04      1074  |   -32.18   32.65  300000  |     0.00      0.43
2023-10-05 16:22:02,033 [INFO] | 8.00e+04      1425  |   -14.46   13.11  300000  |     0.00      0.43
2023-10-05 16:28:00,223 [INFO] | 1.00e+05      1784  |    -7.85   14.37  300000  |     0.00      0.42
2023-10-05 16:37:14,676 [INFO] price_array: 72540
2023-10-05 16:37:14,680 [INFO] | load actor from: ./trained_models/trainer6-96bb7-steps-300000[256, 128]-2019-01-01/actor.pth
2023-10-05 16:37:23,957 [INFO] Test Finished!
2023-10-05 16:37:23,957 [INFO] episode_return: 1.1283072595319756
2023-10-05 17:28:32,703 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 17:30:52,699 [INFO] | 2.00e+04       140  |     0.88    0.99  100000  |     0.00      0.42
2023-10-05 17:32:59,548 [INFO] | 4.00e+04       267  |     0.66    0.71  100000  |     0.00      0.44
2023-10-05 17:35:11,540 [INFO] | 6.00e+04       399  |     0.33    0.58  100000  |     0.00      0.43
2023-10-05 17:37:19,919 [INFO] | 8.00e+04       527  |     0.98    0.31  100000  |     0.00      0.42
2023-10-05 17:39:29,984 [INFO] | 1.00e+05       657  |     0.21    0.18  100000  |     0.00      0.43
2023-10-05 17:49:20,500 [INFO] price_array: 72540
2023-10-05 17:49:20,504 [INFO] | load actor from: ./trained_models/trainer6-fe1a1-steps-100000[512, 256, 128]-2019-01-01/actor.pth
2023-10-05 17:49:30,486 [INFO] Test Finished!
2023-10-05 17:49:30,487 [INFO] episode_return: 0.6898716380183716
