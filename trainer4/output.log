2023-10-03 13:08:34,430 [ERROR] trainer4/trainer4.py Failed to reconnect: Already connected
Traceback (most recent call last):
  File "/Users/miguellopes/Documents/pod-trader/trainer4/trainer4.py", line 102, in disconnect
    sio.connect('http://localhost:5678')
  File "/Users/miguellopes/miniforge3/envs/trader/lib/python3.10/site-packages/socketio/client.py", line 306, in connect
    raise exceptions.ConnectionError('Already connected')
socketio.exceptions.ConnectionError: Already connected
2023-10-03 13:08:34,644 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 13:10:01,955 [ERROR] packet queue is empty, aborting
2023-10-03 16:31:55,736 [ERROR] trainer4/trainer4.py Failed to reconnect: Already connected
Traceback (most recent call last):
  File "/Users/miguellopes/Documents/pod-trader/trainer4/trainer4.py", line 102, in disconnect
    sio.connect('http://localhost:5678')
  File "/Users/miguellopes/miniforge3/envs/trader/lib/python3.10/site-packages/socketio/client.py", line 306, in connect
    raise exceptions.ConnectionError('Already connected')
socketio.exceptions.ConnectionError: Already connected
2023-10-03 17:16:51,986 [ERROR] packet queue is empty, aborting
2023-10-03 17:22:58,718 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-03 17:25:39,080 [INFO] | 2.00e+04       160  |    44.49    0.73  300000  |     0.26      0.03
2023-10-03 17:28:20,137 [INFO] | 4.00e+04       321  |    43.65    1.01  300000  |     0.41      0.03
2023-10-03 17:31:05,705 [INFO] | 6.00e+04       487  |    43.92    1.17  300000  |     0.53      0.01
2023-10-03 17:33:46,400 [INFO] | 8.00e+04       648  |    43.55    1.42  300000  |     0.29      0.00
2023-10-03 17:36:27,044 [INFO] | 1.00e+05       808  |    44.01    1.20  300000  |     0.52      0.01
2023-10-03 17:38:54,179 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-03 17:42:27,444 [INFO] | 2.00e+04       213  |    43.63    1.34  300000  |     0.29      0.01
2023-10-05 10:31:46,338 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 10:38:01,748 [INFO] | 2.00e+04       375  |     9.68   11.22  300000  |     0.01      0.43
2023-10-05 10:44:13,708 [INFO] | 4.00e+04       747  |    10.65    4.97  300000  |     0.00      0.45
2023-10-05 10:50:20,050 [INFO] | 6.00e+04      1114  |     2.03    3.21  300000  |     0.00      0.43
2023-10-05 10:56:26,534 [INFO] | 8.00e+04      1480  |     7.26    3.53  300000  |     0.00      0.43
2023-10-05 11:02:28,784 [INFO] | 1.00e+05      1842  |    13.04    6.47  300000  |     0.00      0.43
2023-10-05 11:11:10,788 [INFO] price_array: 72540
2023-10-05 11:11:10,790 [INFO] | load actor from: ./trained_models/trainer4-87cd7-steps-300000[256, 128]-2019-01-01/actor.pth
2023-10-05 11:11:21,046 [INFO] Test Finished!
2023-10-05 11:11:21,047 [INFO] episode_return: 1.260114880169666
2023-10-05 13:23:15,254 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 13:29:39,506 [INFO] | 2.00e+04       384  |     7.80    7.41  300000  |     0.00      0.44
2023-10-05 13:35:57,014 [INFO] | 4.00e+04       762  |     4.46    8.08  300000  |     0.00      0.43
2023-10-05 13:42:18,887 [INFO] | 6.00e+04      1144  |    -0.51    7.46  300000  |     0.00      0.42
2023-10-05 13:48:26,875 [INFO] | 8.00e+04      1512  |     5.76    6.36  300000  |     0.00      0.46
2023-10-05 13:54:29,281 [INFO] | 1.00e+05      1874  |    -0.15    7.86  300000  |     0.00      0.42
2023-10-05 14:02:55,798 [INFO] price_array: 72540
2023-10-05 14:02:55,800 [INFO] | load actor from: ./trained_models/trainer4-a9ac7-steps-300000[256, 128]-2019-01-01/actor.pth
2023-10-05 14:03:06,803 [INFO] Test Finished!
2023-10-05 14:03:06,803 [INFO] episode_return: 1.7773084867574533
2023-10-05 14:59:44,778 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 15:01:52,508 [INFO] | 2.00e+04       128  |     0.22    0.23  100000  |     0.00      0.43
2023-10-05 15:04:00,307 [INFO] | 4.00e+04       256  |     0.08    0.18  100000  |     0.00      0.44
2023-10-05 15:06:09,468 [INFO] | 6.00e+04       385  |     0.10    0.18  100000  |     0.00      0.42
2023-10-05 15:08:15,340 [INFO] | 8.00e+04       511  |     1.13    1.22  100000  |     0.00      0.42
2023-10-05 15:10:09,691 [INFO] | 1.00e+05       625  |    -0.23    0.10  100000  |     0.00      0.43
2023-10-05 15:19:09,591 [INFO] price_array: 72540
2023-10-05 15:19:09,594 [INFO] | load actor from: ./trained_models/trainer4-65b8e-steps-100000[256, 128, 64]-2019-01-01/actor.pth
2023-10-05 15:19:19,438 [INFO] Test Finished!
2023-10-05 15:19:19,440 [INFO] episode_return: 1.0948276711863043
2023-10-05 16:10:32,571 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 16:12:54,841 [INFO] | 2.00e+04       142  |    -0.09    0.05  100000  |     0.00      0.44
2023-10-05 16:15:16,719 [INFO] | 4.00e+04       284  |    -0.09    0.03  100000  |     0.00      0.44
2023-10-05 16:17:40,298 [INFO] | 6.00e+04       428  |    -0.09    0.04  100000  |     0.00      0.42
2023-10-05 16:19:54,610 [INFO] | 8.00e+04       562  |    -0.12    0.04  100000  |     0.00      0.42
2023-10-05 16:22:04,938 [INFO] | 1.00e+05       692  |    -0.14    0.05  100000  |     0.00      0.43
2023-10-05 16:31:17,078 [INFO] price_array: 72540
2023-10-05 16:31:17,082 [INFO] | load actor from: ./trained_models/trainer4-4f340-steps-100000[512, 256]-2019-01-01/actor.pth
2023-10-05 16:31:27,096 [INFO] Test Finished!
2023-10-05 16:31:27,096 [INFO] episode_return: 1.0492429739865308
2023-10-05 17:22:44,761 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 17:29:38,769 [INFO] | 2.00e+04       414  |    -1.04    5.15  300000  |     0.00      0.43
2023-10-05 17:36:25,166 [INFO] | 4.00e+04       820  |    -2.14    3.44  300000  |     0.00      0.43
2023-10-05 17:43:10,881 [INFO] | 6.00e+04      1226  |    -1.44   27.79  300000  |     0.00      0.42
2023-10-05 17:49:38,146 [INFO] | 8.00e+04      1613  |     2.15   15.67  300000  |     0.00      0.43
2023-10-05 17:55:59,905 [INFO] | 1.00e+05      1995  |    18.33   15.97  300000  |     0.00      0.42
2023-10-05 18:04:36,677 [INFO] price_array: 72540
2023-10-05 18:04:36,680 [INFO] | load actor from: ./trained_models/trainer4-25c28-steps-300000[512, 256, 128]-2019-01-01/actor.pth
2023-10-05 18:04:47,003 [INFO] Test Finished!
2023-10-05 18:04:47,005 [INFO] episode_return: 1.8261091053934098
