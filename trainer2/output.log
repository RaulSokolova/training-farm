2023-10-03 12:40:31,833 [ERROR] trainer2/trainer2.py Failed to reconnect: Already connected
Traceback (most recent call last):
  File "/Users/miguellopes/Documents/pod-trader/trainer2/trainer2.py", line 102, in disconnect
    sio.connect('http://localhost:5678')
  File "/Users/miguellopes/miniforge3/envs/trader/lib/python3.10/site-packages/socketio/client.py", line 306, in connect
    raise exceptions.ConnectionError('Already connected')
socketio.exceptions.ConnectionError: Already connected
2023-10-03 12:40:33,269 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 13:08:26,885 [ERROR] trainer2/trainer2.py Failed to reconnect: Already connected
Traceback (most recent call last):
  File "/Users/miguellopes/Documents/pod-trader/trainer2/trainer2.py", line 102, in disconnect
    sio.connect('http://localhost:5678')
  File "/Users/miguellopes/miniforge3/envs/trader/lib/python3.10/site-packages/socketio/client.py", line 306, in connect
    raise exceptions.ConnectionError('Already connected')
socketio.exceptions.ConnectionError: Already connected
2023-10-03 13:08:27,349 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 13:10:04,788 [ERROR] packet queue is empty, aborting
2023-10-03 15:02:43,424 [ERROR] packet queue is empty, aborting
2023-10-03 16:30:57,687 [ERROR] trainer2/trainer2.py Failed to reconnect: Already connected
Traceback (most recent call last):
  File "/Users/miguellopes/Documents/pod-trader/trainer2/trainer2.py", line 102, in disconnect
    sio.connect('http://localhost:5678')
  File "/Users/miguellopes/miniforge3/envs/trader/lib/python3.10/site-packages/socketio/client.py", line 306, in connect
    raise exceptions.ConnectionError('Already connected')
socketio.exceptions.ConnectionError: Already connected
2023-10-03 16:32:14,790 [ERROR] trainer2/trainer2.py Failed to reconnect: Already connected
Traceback (most recent call last):
  File "/Users/miguellopes/Documents/pod-trader/trainer2/trainer2.py", line 102, in disconnect
    sio.connect('http://localhost:5678')
  File "/Users/miguellopes/miniforge3/envs/trader/lib/python3.10/site-packages/socketio/client.py", line 306, in connect
    raise exceptions.ConnectionError('Already connected')
socketio.exceptions.ConnectionError: Already connected
2023-10-03 16:32:17,987 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:18,177 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:18,816 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:18,820 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:19,019 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:19,026 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:19,068 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:19,120 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:19,158 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:19,174 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:19,250 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:19,252 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:19,265 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:19,268 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:19,276 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:19,281 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:19,283 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:19,284 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:19,309 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:19,309 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:19,331 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:19,393 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:19,419 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:19,494 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:19,606 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:19,643 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:19,750 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:19,923 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:20,072 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:20,166 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:20,478 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:20,508 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:20,546 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:20,663 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:20,898 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:20,911 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:20,979 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:21,084 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:21,122 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:21,241 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:21,328 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:21,459 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:21,507 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:21,569 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:21,675 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:22,025 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:22,148 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:22,242 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:22,704 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:22,870 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:22,877 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:22,896 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:23,101 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:23,119 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:23,207 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:23,370 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:23,537 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:23,650 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:23,768 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:23,987 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:24,081 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:24,257 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:24,344 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:24,472 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:24,534 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:24,715 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:24,771 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:24,858 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:25,063 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:25,267 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:25,373 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:25,498 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:25,528 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:25,597 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:25,647 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:25,839 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:25,988 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:26,063 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:26,181 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:26,293 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:26,348 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:26,454 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:26,497 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:26,590 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:26,776 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:26,825 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:26,951 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:27,051 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:27,162 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:27,338 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:27,375 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:27,437 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:27,555 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:27,618 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:27,693 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:27,749 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:27,892 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 16:32:27,942 [WARNING] Namespace error occurred: / is not a connected namespace.
2023-10-03 17:16:50,111 [ERROR] packet queue is empty, aborting
2023-10-03 17:22:59,168 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-03 17:24:44,765 [INFO] | 2.00e+04       106  |   -76.24    1.93  200000  |     0.26      0.02
2023-10-03 17:26:31,265 [INFO] | 4.00e+04       212  |   -75.97    1.69  200000  |     0.44      0.00
2023-10-03 17:28:17,189 [INFO] | 6.00e+04       318  |   -75.32    2.22  200000  |     0.55      0.00
2023-10-03 17:30:06,084 [INFO] | 8.00e+04       427  |   -75.87    1.37  200000  |     0.31      0.02
2023-10-03 17:31:54,622 [INFO] | 1.00e+05       535  |   -76.97    2.17  200000  |     0.55      0.01
2023-10-03 17:34:24,996 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-03 17:37:08,275 [INFO] | 2.00e+04       163  |   -11.70    0.60  300000  |     0.17      0.02
2023-10-03 17:39:53,525 [INFO] | 4.00e+04       329  |     4.68    1.94  300000  |     0.19      0.01
2023-10-03 17:42:41,650 [INFO] | 6.00e+04       497  |    -8.90    1.58  300000  |     0.13      0.02
2023-10-03 18:08:49,193 [ERROR] packet queue is empty, aborting
2023-10-03 19:26:43,124 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-03 19:30:41,015 [INFO] | 2.00e+04       238  |   -66.16    9.91  200000  |     0.00      0.42
2023-10-03 19:34:40,641 [INFO] | 4.00e+04       478  |   -68.48   17.26  200000  |     0.00      0.44
2023-10-03 19:38:37,087 [INFO] | 6.00e+04       714  |   -62.40   18.94  200000  |     0.00      0.42
2023-10-03 19:42:37,720 [INFO] | 8.00e+04       955  |   -86.07    6.80  200000  |     0.00      0.42
2023-10-03 19:46:32,729 [INFO] | 1.00e+05      1190  |   -83.57   54.14  200000  |     0.00      0.42
2023-10-03 21:06:58,942 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-03 21:10:42,906 [INFO] | 2.00e+04       224  |  -114.67    5.39  200000  |     0.00      0.43
2023-10-03 21:14:23,878 [INFO] | 4.00e+04       445  |  -112.69    3.81  200000  |     0.08      0.42
2023-10-03 21:18:04,035 [INFO] | 6.00e+04       665  |  -115.27    4.64  200000  |     0.01      0.45
2023-10-03 21:21:38,482 [INFO] | 8.00e+04       880  |  -116.65    2.94  200000  |     0.00      0.42
2023-10-03 21:25:14,133 [INFO] | 1.00e+05      1095  |  -115.31    5.03  200000  |     0.00      0.42
2023-10-04 20:29:07,439 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-04 20:32:58,811 [INFO] | 2.00e+04       231  |    14.84    6.63  200000  |     0.00      0.42
2023-10-04 22:19:38,367 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-04 22:23:14,877 [INFO] | 2.00e+04       217  |  -112.59    9.70  200000  |     0.00      0.43
2023-10-04 22:26:53,411 [INFO] | 4.00e+04       435  |  -116.65   11.62  200000  |     0.21      0.42
2023-10-04 22:30:29,900 [INFO] | 6.00e+04       652  |  -114.16   12.47  200000  |     0.20      0.43
2023-10-04 22:34:03,547 [INFO] | 8.00e+04       865  |  -132.97   10.13  200000  |     0.07      0.41
2023-10-04 22:37:35,595 [INFO] | 1.00e+05      1077  |  -120.10   11.27  200000  |     0.05      0.43
2023-10-04 23:21:59,490 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-04 23:25:33,374 [INFO] | 2.00e+04       214  |    26.13    2.94  200000  |     0.00      0.43
2023-10-04 23:29:07,354 [INFO] | 4.00e+04       428  |    33.06    2.94  200000  |     0.01      0.44
2023-10-04 23:32:43,145 [INFO] | 6.00e+04       644  |    36.94    3.15  200000  |     0.00      0.43
2023-10-04 23:36:24,703 [INFO] | 8.00e+04       865  |    32.92    3.62  200000  |     0.00      0.43
2023-10-04 23:40:05,883 [INFO] | 1.00e+05      1086  |    35.93    5.24  200000  |     0.00      0.42
2023-10-05 00:27:37,103 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 00:31:31,942 [INFO] | 2.00e+04       235  |   165.01    5.31  200000  |     0.00      0.45
2023-10-05 00:35:23,875 [INFO] | 4.00e+04       467  |   162.36    6.72  200000  |     0.06      0.44
2023-10-05 00:39:41,582 [INFO] | 6.00e+04       724  |   164.77    6.13  200000  |     0.23      0.44
2023-10-05 00:43:47,417 [INFO] | 8.00e+04       970  |   157.84    7.56  200000  |     0.02      0.42
2023-10-05 00:47:53,154 [INFO] | 1.00e+05      1216  |   158.89    5.22  200000  |     0.01      0.42
2023-10-05 01:10:30,139 [ERROR] trainer2/trainer2.py Failed to reconnect: Already connected
Traceback (most recent call last):
  File "/Users/miguellopes/Documents/pod-trader/trainer2/trainer2.py", line 102, in disconnect
    sio.connect('http://localhost:5678')
  File "/Users/miguellopes/miniforge3/envs/trader/lib/python3.10/site-packages/socketio/client.py", line 306, in connect
    raise exceptions.ConnectionError('Already connected')
socketio.exceptions.ConnectionError: Already connected
2023-10-05 01:33:55,191 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 01:38:53,726 [INFO] | 2.00e+04       299  |   -66.94    5.62  200000  |     0.00      0.44
2023-10-05 01:48:13,250 [INFO] | 4.00e+04       858  |   -73.03    2.00  200000  |     0.21      0.44
2023-10-05 01:54:15,539 [INFO] | 6.00e+04      1220  |   -74.55    3.84  200000  |     0.24      0.45
2023-10-05 01:58:55,080 [INFO] | 8.00e+04      1500  |   -69.29    3.08  200000  |     0.10      0.43
2023-10-05 02:03:30,044 [INFO] | 1.00e+05      1775  |   -57.38    5.61  200000  |     0.15      0.43
2023-10-05 02:50:08,776 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 02:52:02,870 [INFO] | 2.00e+04       114  |   141.20    4.34  100000  |     0.00      0.44
2023-10-05 02:53:59,724 [INFO] | 4.00e+04       231  |   144.92    4.27  100000  |     0.00      0.44
2023-10-05 02:55:53,610 [INFO] | 6.00e+04       345  |   138.13    5.55  100000  |     0.00      0.44
2023-10-05 02:57:48,225 [INFO] | 8.00e+04       459  |   138.10    5.45  100000  |     0.00      0.43
2023-10-05 02:59:42,495 [INFO] | 1.00e+05       574  |   138.71    5.56  100000  |     0.00      0.41
2023-10-05 03:23:59,913 [ERROR] trainer2/trainer2.py Failed to reconnect: Already connected
Traceback (most recent call last):
  File "/Users/miguellopes/Documents/pod-trader/trainer2/trainer2.py", line 102, in disconnect
    sio.connect('http://localhost:5678')
  File "/Users/miguellopes/miniforge3/envs/trader/lib/python3.10/site-packages/socketio/client.py", line 306, in connect
    raise exceptions.ConnectionError('Already connected')
socketio.exceptions.ConnectionError: Already connected
2023-10-05 03:46:53,130 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 03:52:03,000 [INFO] | 2.00e+04       310  |   104.00    4.84  300000  |     0.00      0.43
2023-10-05 03:57:14,018 [INFO] | 4.00e+04       621  |    96.43    6.85  300000  |     0.00      0.44
2023-10-05 04:02:29,082 [INFO] | 6.00e+04       936  |    95.84    5.95  300000  |     0.00      0.42
2023-10-05 04:07:37,876 [INFO] | 8.00e+04      1245  |    95.46    3.40  300000  |     0.00      0.44
2023-10-05 04:12:47,117 [INFO] | 1.00e+05      1554  |    95.54    8.18  300000  |     0.00      0.44
2023-10-05 04:58:55,873 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 05:01:03,401 [INFO] | 2.00e+04       128  |    72.31    2.18  100000  |     0.00      0.44
2023-10-05 05:03:08,430 [INFO] | 4.00e+04       253  |    69.43    2.00  100000  |     0.11      0.42
2023-10-05 05:05:15,467 [INFO] | 6.00e+04       380  |    72.30    2.76  100000  |     0.17      0.44
2023-10-05 05:07:25,192 [INFO] | 8.00e+04       509  |    74.10    1.91  100000  |     0.13      0.44
2023-10-05 05:09:36,040 [INFO] | 1.00e+05       640  |    69.81    2.71  100000  |     0.09      0.45
2023-10-05 05:55:13,297 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 06:00:39,417 [INFO] | 2.00e+04       326  |   278.37   75.29  300000  |     0.01      0.44
2023-10-05 06:06:11,391 [INFO] | 4.00e+04       658  |   283.00   96.31  300000  |     0.07      0.44
2023-10-05 06:11:53,779 [INFO] | 6.00e+04      1000  |   207.43   65.34  300000  |     0.00      0.42
2023-10-05 06:17:26,936 [INFO] | 8.00e+04      1334  |   239.31   30.75  300000  |     0.00      0.41
2023-10-05 06:23:00,918 [INFO] | 1.00e+05      1668  |   236.14   41.06  300000  |     0.00      0.43
2023-10-05 07:11:21,059 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 07:13:19,467 [INFO] | 2.00e+04       118  |    38.29    5.84  100000  |     0.00      0.43
2023-10-05 07:15:20,062 [INFO] | 4.00e+04       239  |    37.48    4.98  100000  |     0.07      0.41
2023-10-05 07:17:17,583 [INFO] | 6.00e+04       357  |    34.98    3.93  100000  |     0.00      0.42
2023-10-05 07:19:16,937 [INFO] | 8.00e+04       476  |    34.94    1.43  100000  |     0.00      0.43
2023-10-05 07:21:16,301 [INFO] | 1.00e+05       595  |    33.39    1.55  100000  |     0.00      0.43
2023-10-05 09:18:46,941 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 10:22:31,047 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 10:26:52,893 [INFO] | 2.00e+04       262  |    93.28    5.11  200000  |     0.00      0.43
2023-10-05 10:31:12,749 [INFO] | 4.00e+04       522  |    84.27    3.72  200000  |     0.00      0.45
2023-10-05 10:35:35,283 [INFO] | 6.00e+04       784  |    81.31    3.09  200000  |     0.00      0.44
2023-10-05 10:39:53,901 [INFO] | 8.00e+04      1043  |    83.34    4.00  200000  |     0.00      0.43
2023-10-05 10:44:21,787 [INFO] | 1.00e+05      1311  |    85.47    5.01  200000  |     0.00      0.43
2023-10-05 10:53:04,968 [INFO] price_array: 72540
2023-10-05 10:53:04,970 [INFO] | load actor from: ./trained_models/trainer2-91854-steps-200000[128, 64]-2019-01-01/actor.pth
2023-10-05 10:53:15,881 [INFO] Test Finished!
2023-10-05 10:53:15,881 [INFO] episode_return: 1.2113412133519705
2023-10-05 13:14:10,027 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 13:18:03,378 [INFO] | 2.00e+04       233  |    66.83    3.64  200000  |     0.00      0.44
2023-10-05 13:22:03,150 [INFO] | 4.00e+04       473  |    75.64    5.33  200000  |     0.00      0.43
2023-10-05 13:26:01,531 [INFO] | 6.00e+04       712  |    62.19    4.14  200000  |     0.00      0.42
2023-10-05 13:30:02,987 [INFO] | 8.00e+04       953  |    63.69    6.31  200000  |     0.00      0.43
2023-10-05 13:33:59,267 [INFO] | 1.00e+05      1189  |    69.14    2.89  200000  |     0.00      0.42
2023-10-05 13:42:55,041 [INFO] price_array: 72540
2023-10-05 13:42:55,043 [INFO] | load actor from: ./trained_models/trainer2-366fb-steps-200000[128, 64]-2019-01-01/actor.pth
2023-10-05 13:43:05,552 [INFO] Test Finished!
2023-10-05 13:43:05,553 [INFO] episode_return: 1.4699197927903822
2023-10-05 14:31:21,595 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 14:34:01,770 [INFO] | 2.00e+04       160  |    -0.04    0.03  100000  |     0.00      0.44
2023-10-05 14:36:48,817 [INFO] | 4.00e+04       327  |    -0.01    0.04  100000  |     0.00      0.44
2023-10-05 14:39:33,946 [INFO] | 6.00e+04       492  |    -0.02    0.04  100000  |     0.00      0.43
2023-10-05 14:42:16,648 [INFO] | 8.00e+04       655  |    -0.03    0.03  100000  |     0.00      0.44
2023-10-05 14:45:12,392 [INFO] | 1.00e+05       831  |    -0.03    0.03  100000  |     0.00      0.44
2023-10-05 14:54:13,209 [INFO] price_array: 72540
2023-10-05 14:54:13,216 [INFO] | load actor from: ./trained_models/trainer2-ea6f2-steps-100000[1024, 512]-2019-01-01/actor.pth
2023-10-05 14:54:25,436 [INFO] Test Finished!
2023-10-05 14:54:25,436 [INFO] episode_return: 1.320085847732497
2023-10-05 15:44:41,258 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 15:51:06,071 [INFO] | 2.00e+04       385  |   -24.18    7.61  300000  |     0.00      0.42
2023-10-05 15:57:29,071 [INFO] | 4.00e+04       768  |   -31.21   12.97  300000  |     0.00      0.42
2023-10-05 16:04:09,098 [INFO] | 6.00e+04      1168  |   -35.68   13.92  300000  |     0.00      0.42
2023-10-05 16:10:50,388 [INFO] | 8.00e+04      1569  |   -32.60   10.39  300000  |     0.00      0.42
2023-10-05 16:17:30,995 [INFO] | 1.00e+05      1970  |   -17.36    7.78  300000  |     0.00      0.43
2023-10-05 16:27:07,509 [INFO] price_array: 72540
2023-10-05 16:27:07,511 [INFO] | load actor from: ./trained_models/trainer2-e8bb2-steps-300000[128, 64]-2019-01-01/actor.pth
2023-10-05 16:27:17,987 [INFO] Test Finished!
2023-10-05 16:27:17,988 [INFO] episode_return: 1.56132918747778
2023-10-05 17:18:35,150 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 17:24:11,367 [INFO] | 2.00e+04       336  |     3.65    1.13  300000  |     0.00      0.43
2023-10-05 17:29:52,740 [INFO] | 4.00e+04       678  |     3.72    1.77  300000  |     0.00      0.42
2023-10-05 17:35:37,986 [INFO] | 6.00e+04      1023  |     7.28    1.74  300000  |     0.00      0.43
2023-10-05 17:41:29,937 [INFO] | 8.00e+04      1375  |     7.68    3.16  300000  |     0.00      0.44
2023-10-05 17:47:19,638 [INFO] | 1.00e+05      1724  |     7.29    3.60  300000  |     0.00      0.43
2023-10-05 17:56:37,153 [INFO] price_array: 72540
2023-10-05 17:56:37,156 [INFO] | load actor from: ./trained_models/trainer2-a422c-steps-300000[256, 128, 64]-2019-01-01/actor.pth
2023-10-05 17:56:46,620 [INFO] Test Finished!
2023-10-05 17:56:46,620 [INFO] episode_return: 1.0812361257910732
2023-10-05 18:45:11,835 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 18:47:34,486 [INFO] | 2.00e+04       143  |    -0.05    0.04  100000  |     0.00      0.42
2023-10-05 18:49:56,304 [INFO] | 4.00e+04       284  |    -0.04    0.05  100000  |     0.00      0.44
2023-10-05 18:52:31,962 [INFO] | 6.00e+04       440  |    -0.05    0.04  100000  |     0.00      0.43
2023-10-05 18:54:56,736 [INFO] | 8.00e+04       585  |     0.07    0.17  100000  |     0.00      0.43
2023-10-05 18:57:18,349 [INFO] | 1.00e+05       727  |     2.62    3.23  100000  |     0.00      0.44
2023-10-05 19:07:01,953 [INFO] price_array: 72540
2023-10-05 19:07:01,960 [INFO] | load actor from: ./trained_models/trainer2-fcff0-steps-100000[1024, 512]-2019-01-01/actor.pth
2023-10-05 19:07:13,176 [INFO] Test Finished!
2023-10-05 19:07:13,177 [INFO] episode_return: 1.1691296909398092
2023-10-05 19:59:04,116 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 20:02:39,849 [INFO] | 2.00e+04       216  |     1.04    5.09  200000  |     0.01      0.43
2023-10-05 20:06:18,674 [INFO] | 4.00e+04       435  |     0.21    3.84  200000  |     0.00      0.42
2023-10-05 20:09:57,108 [INFO] | 6.00e+04       653  |    -0.65    4.46  200000  |     0.00      0.44
2023-10-05 20:13:39,668 [INFO] | 8.00e+04       876  |     2.28    3.67  200000  |     0.00      0.43
2023-10-05 20:17:21,075 [INFO] | 1.00e+05      1097  |     0.87    2.24  200000  |     0.00      0.44
2023-10-05 20:27:26,118 [INFO] price_array: 72540
2023-10-05 20:27:26,120 [INFO] | load actor from: ./trained_models/trainer2-8ddf1-steps-200000[128, 64]-2019-01-01/actor.pth
2023-10-05 20:27:35,162 [INFO] Test Finished!
2023-10-05 20:27:35,162 [INFO] episode_return: 0.9007506811015134
2023-10-05 21:22:49,867 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 21:24:43,664 [INFO] | 2.00e+04       114  |     0.03    0.04  100000  |     0.00      0.43
2023-10-05 21:26:40,900 [INFO] | 4.00e+04       231  |     0.00    0.05  100000  |     0.00      0.44
2023-10-05 21:28:35,901 [INFO] | 6.00e+04       346  |     0.03    0.04  100000  |     0.00      0.42
2023-10-05 21:30:30,351 [INFO] | 8.00e+04       460  |     0.04    0.04  100000  |     0.00      0.43
2023-10-05 21:32:25,895 [INFO] | 1.00e+05       576  |     0.07    0.04  100000  |     0.00      0.43
2023-10-05 21:42:42,324 [INFO] price_array: 72540
2023-10-05 21:42:42,326 [INFO] | load actor from: ./trained_models/trainer2-25998-steps-100000[128, 64, 32]-2019-01-01/actor.pth
2023-10-05 21:42:51,693 [INFO] Test Finished!
2023-10-05 21:42:51,694 [INFO] episode_return: 1.446806915106249
2023-10-05 22:39:46,800 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-05 22:43:49,243 [INFO] | 2.00e+04       242  |     7.57    3.79  200000  |     0.00      0.44
2023-10-05 22:47:41,690 [INFO] | 4.00e+04       475  |     6.83    3.44  200000  |     0.00      0.43
2023-10-05 22:51:46,495 [INFO] | 6.00e+04       720  |     7.70    3.54  200000  |     0.00      0.45
2023-10-05 22:56:10,598 [INFO] | 8.00e+04       984  |    13.59    6.19  200000  |     0.00      0.42
2023-10-05 23:00:41,947 [INFO] | 1.00e+05      1255  |    17.41    4.37  200000  |     0.00      0.42
2023-10-05 23:09:46,945 [INFO] price_array: 72540
2023-10-05 23:09:46,949 [INFO] | load actor from: ./trained_models/trainer2-29210-steps-200000[512, 256]-2019-01-01/actor.pth
2023-10-05 23:09:56,996 [INFO] Test Finished!
2023-10-05 23:09:56,997 [INFO] episode_return: 0.773762761262424
2023-10-05 23:57:46,399 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-06 00:03:41,346 [INFO] | 2.00e+04       355  |    30.90   11.35  300000  |     0.00      0.42
2023-10-06 00:09:34,641 [INFO] | 4.00e+04       708  |    27.79   10.69  300000  |     0.00      0.42
2023-10-06 00:15:30,008 [INFO] | 6.00e+04      1064  |    34.70    9.34  300000  |     0.00      0.43
2023-10-06 00:21:25,478 [INFO] | 8.00e+04      1419  |    24.24    8.84  300000  |     0.00      0.43
2023-10-06 00:27:15,032 [INFO] | 1.00e+05      1769  |    37.14    8.36  300000  |     0.00      0.43
2023-10-06 00:36:02,332 [INFO] price_array: 72540
2023-10-06 00:36:02,334 [INFO] | load actor from: ./trained_models/trainer2-b7645-steps-300000[128, 64]-2019-01-01/actor.pth
2023-10-06 00:36:11,448 [INFO] Test Finished!
2023-10-06 00:36:11,448 [INFO] episode_return: 1.4551254653829586
2023-10-06 01:25:00,290 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-06 01:27:07,598 [INFO] | 2.00e+04       127  |     0.02    0.03  100000  |     0.00      0.42
2023-10-06 01:29:14,253 [INFO] | 4.00e+04       254  |     0.03    0.02  100000  |     0.00      0.42
2023-10-06 01:31:17,870 [INFO] | 6.00e+04       378  |     0.03    0.02  100000  |     0.00      0.43
2023-10-06 01:33:21,144 [INFO] | 8.00e+04       501  |     0.04    0.03  100000  |     0.00      0.43
2023-10-06 01:35:34,046 [INFO] | 1.00e+05       634  |     0.04    0.04  100000  |     0.00      0.43
2023-10-06 01:44:27,117 [INFO] price_array: 72540
2023-10-06 01:44:27,120 [INFO] | load actor from: ./trained_models/trainer2-8f582-steps-100000[128, 64, 32]-2019-01-01/actor.pth
2023-10-06 01:44:37,681 [INFO] Test Finished!
2023-10-06 01:44:37,681 [INFO] episode_return: 1.531768946515179
2023-10-06 02:32:29,763 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-06 02:38:11,398 [INFO] | 2.00e+04       342  |    -5.29    5.46  300000  |     0.00      0.43
2023-10-06 02:43:58,469 [INFO] | 4.00e+04       689  |    -4.78    4.38  300000  |     0.00      0.44
2023-10-06 02:49:39,323 [INFO] | 6.00e+04      1030  |    -6.19    8.58  300000  |     0.00      0.43
2023-10-06 02:55:25,245 [INFO] | 8.00e+04      1375  |    -5.57    4.64  300000  |     0.00      0.43
2023-10-06 03:01:09,611 [INFO] | 1.00e+05      1720  |    -3.79    6.11  300000  |     0.00      0.42
2023-10-06 03:11:08,794 [INFO] price_array: 72540
2023-10-06 03:11:08,796 [INFO] | load actor from: ./trained_models/trainer2-d803c-steps-300000[128, 64]-2019-01-01/actor.pth
2023-10-06 03:11:17,838 [INFO] Test Finished!
2023-10-06 03:11:17,838 [INFO] episode_return: 0.9613131890833869
2023-10-06 04:01:26,620 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-06 04:05:27,358 [INFO] | 2.00e+04       241  |     9.93   20.91  200000  |     0.00      0.42
2023-10-06 04:09:24,893 [INFO] | 4.00e+04       478  |    16.77   17.25  200000  |     0.00      0.43
2023-10-06 04:13:09,979 [INFO] | 6.00e+04       703  |    21.27   13.37  200000  |     0.00      0.43
2023-10-06 04:17:02,078 [INFO] | 8.00e+04       935  |    23.13   13.24  200000  |     0.00      0.42
2023-10-06 04:20:52,802 [INFO] | 1.00e+05      1166  |    11.97   20.27  200000  |     0.00      0.42
2023-10-06 04:29:31,381 [INFO] price_array: 72540
2023-10-06 04:29:31,385 [INFO] | load actor from: ./trained_models/trainer2-729b3-steps-200000[256, 128, 64]-2019-01-01/actor.pth
2023-10-06 04:29:40,601 [INFO] Test Finished!
2023-10-06 04:29:40,601 [INFO] episode_return: 1.2644951306259644
2023-10-06 05:17:57,574 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-06 05:20:20,172 [INFO] | 2.00e+04       143  |    -0.02    0.04  100000  |     0.00      0.42
2023-10-06 05:22:39,117 [INFO] | 4.00e+04       282  |    -0.04    0.04  100000  |     0.00      0.42
2023-10-06 05:24:48,304 [INFO] | 6.00e+04       411  |    -0.03    0.03  100000  |     0.00      0.43
2023-10-06 05:26:59,189 [INFO] | 8.00e+04       542  |    -0.04    0.04  100000  |     0.00      0.43
2023-10-06 05:29:22,153 [INFO] | 1.00e+05       685  |    -0.05    0.04  100000  |     0.00      0.42
2023-10-06 05:37:45,497 [INFO] price_array: 72540
2023-10-06 05:37:45,501 [INFO] | load actor from: ./trained_models/trainer2-3336f-steps-100000[512, 256]-2019-01-01/actor.pth
2023-10-06 05:37:56,165 [INFO] Test Finished!
2023-10-06 05:37:56,165 [INFO] episode_return: 0.922341527406552
2023-10-06 06:23:53,066 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-06 06:25:41,415 [INFO] | 2.00e+04       108  |    -0.22    2.24  100000  |     0.00      0.43
2023-10-06 06:27:23,919 [INFO] | 4.00e+04       211  |    -0.04    1.68  100000  |     0.00      0.41
2023-10-06 06:29:03,971 [INFO] | 6.00e+04       311  |    -0.56    1.28  100000  |     0.00      0.40
2023-10-06 06:30:44,005 [INFO] | 8.00e+04       411  |     1.56    2.95  100000  |     0.00      0.44
2023-10-06 06:32:27,925 [INFO] | 1.00e+05       515  |     2.16    3.49  100000  |     0.00      0.41
2023-10-06 06:40:39,312 [INFO] price_array: 72540
2023-10-06 06:40:39,316 [INFO] | load actor from: ./trained_models/trainer2-59a69-steps-100000[256, 128, 64]-2019-01-01/actor.pth
2023-10-06 06:40:48,768 [INFO] Test Finished!
2023-10-06 06:40:48,768 [INFO] episode_return: 1.1431057821114543
2023-10-06 07:27:19,151 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-06 07:33:09,800 [INFO] | 2.00e+04       351  |    -3.17    6.77  300000  |     0.00      0.42
2023-10-06 07:39:25,824 [INFO] | 4.00e+04       727  |    -5.82    7.95  300000  |     0.00      0.43
2023-10-06 07:46:07,000 [INFO] | 6.00e+04      1128  |    -2.44    8.30  300000  |     0.00      0.43
2023-10-06 07:52:55,251 [INFO] | 8.00e+04      1536  |    -9.78    9.71  300000  |     0.00      0.43
2023-10-06 07:59:35,480 [INFO] | 1.00e+05      1936  |    -9.85    6.91  300000  |     0.00      0.43
2023-10-06 08:08:09,800 [INFO] price_array: 72540
2023-10-06 08:08:09,804 [INFO] | load actor from: ./trained_models/trainer2-aac29-steps-300000[512, 256]-2019-01-01/actor.pth
2023-10-06 08:08:20,102 [INFO] Test Finished!
2023-10-06 08:08:20,103 [INFO] episode_return: 1.4763330316777246
2023-10-06 08:55:21,339 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-06 09:01:47,750 [INFO] | 2.00e+04       386  |     3.74    6.10  300000  |     0.00      0.41
2023-10-06 09:08:06,906 [INFO] | 4.00e+04       766  |     3.67    3.82  300000  |     0.00      0.41
2023-10-06 09:14:37,782 [INFO] | 6.00e+04      1156  |     5.61   10.15  300000  |     0.00      0.42
2023-10-06 09:21:12,719 [INFO] | 8.00e+04      1551  |     0.99    8.81  300000  |     0.00      0.43
2023-10-06 09:27:38,377 [INFO] | 1.00e+05      1937  |    -0.75    9.13  300000  |     0.00      0.44
2023-10-06 09:37:58,245 [INFO] price_array: 72540
2023-10-06 09:37:58,248 [INFO] | load actor from: ./trained_models/trainer2-4f689-steps-300000[512, 256, 128]-2019-01-01/actor.pth
2023-10-06 09:38:08,380 [INFO] Test Finished!
2023-10-06 09:38:08,380 [INFO] episode_return: 0.8907112772181037
2023-10-06 10:32:35,001 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-06 10:34:43,459 [INFO] | 2.00e+04       128  |    -0.02    0.04  100000  |     0.00      0.43
2023-10-06 10:36:51,090 [INFO] | 4.00e+04       256  |    -0.02    0.02  100000  |     0.00      0.43
2023-10-06 10:38:57,585 [INFO] | 6.00e+04       383  |    -0.00    0.03  100000  |     0.00      0.42
2023-10-06 10:41:06,191 [INFO] | 8.00e+04       511  |    -0.02    0.03  100000  |     0.00      0.42
2023-10-06 10:43:14,497 [INFO] | 1.00e+05       639  |    -0.04    0.04  100000  |     0.00      0.43
2023-10-06 10:53:04,385 [INFO] price_array: 72540
2023-10-06 10:53:04,387 [INFO] | load actor from: ./trained_models/trainer2-b4d2d-steps-100000[128, 64, 32]-2019-01-01/actor.pth
2023-10-06 10:53:15,036 [INFO] Test Finished!
2023-10-06 10:53:15,037 [INFO] episode_return: 1.391560940530777
2023-10-06 11:45:51,317 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-06 11:52:06,146 [INFO] | 2.00e+04       375  |    11.04    4.37  300000  |     0.01      0.41
2023-10-06 11:58:33,956 [INFO] | 4.00e+04       763  |    14.50    9.11  300000  |     0.00      0.43
2023-10-06 12:05:03,149 [INFO] | 6.00e+04      1152  |    20.03    6.32  300000  |     0.00      0.43
2023-10-06 12:11:29,124 [INFO] | 8.00e+04      1538  |    17.44    9.83  300000  |     0.00      0.43
2023-10-06 12:17:58,087 [INFO] | 1.00e+05      1927  |    13.41    5.46  300000  |     0.00      0.43
2023-10-06 12:28:35,833 [INFO] price_array: 72540
2023-10-06 12:28:35,836 [INFO] | load actor from: ./trained_models/trainer2-cd9b5-steps-300000[256, 128]-2019-01-01/actor.pth
2023-10-06 12:28:46,652 [INFO] Test Finished!
2023-10-06 12:28:46,653 [INFO] episode_return: 0.9712187522018921
2023-10-06 13:20:26,715 [INFO] 
| `step`: Number of samples, or total training steps, or running times of `env.step()`.
| `time`: Time spent from the start of training to this moment.
| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.
| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.
| `avgS`: Average of steps in an episode.
| `objC`: Objective of Critic network. Or call it loss function of critic network.
| `objA`: Objective of Actor network. It is the average Q value of the critic network.
|     step      time  |     avgR    stdR    avgS  |     objC      objA
2023-10-06 13:22:40,787 [INFO] | 2.00e+04       134  |    -0.09    0.09  100000  |     0.00      0.42
2023-10-06 13:24:55,872 [INFO] | 4.00e+04       269  |    -0.12    0.03  100000  |     0.00      0.43
2023-10-06 13:27:10,614 [INFO] | 6.00e+04       404  |    -0.10    0.06  100000  |     0.00      0.43
2023-10-06 13:29:24,258 [INFO] | 8.00e+04       538  |    -0.07    0.09  100000  |     0.00      0.41
2023-10-06 13:31:38,190 [INFO] | 1.00e+05       671  |    -0.04    0.21  100000  |     0.00      0.43
2023-10-06 13:40:36,895 [INFO] price_array: 72540
2023-10-06 13:40:36,898 [INFO] | load actor from: ./trained_models/trainer2-4d3e3-steps-100000[256, 128, 64]-2019-01-01/actor.pth
2023-10-06 13:40:48,134 [INFO] Test Finished!
2023-10-06 13:40:48,135 [INFO] episode_return: 0.849204091080475
